title,authors,year,venue,ee,url,abstract
Reasoning about Network Traffic Load Property at Production Scale.,Ruihan Li; Fangdan Ye; Yifei Yuan 0001; Ruizhen Yang; Bingchuan Tian; Tianchen Guo; Hao Wu; Xiaobo Zhu; Zhongyu Guan; Qing Ma; Xianlong Zeng; Chenren Xu; Dennis Cai; Ennan Zhai,2024,NSDI,https://www.usenix.org/conference/nsdi24/presentation/li-ruihan,https://dblp.org/db/conf/nsdi/nsdi2024.html#LiYYYTGWZGMZXCZ24,"This paper presents Jingubang, the first reported system for checking network traffic load properties (e.g., if any link’s utilization would exceed 80% during a network change) in a production Wide Area Network (WAN). Motivated by our network operators, Jingubang should meet three important requirements: (R1) comprehensive support for complex traffic behavior under BGP, IS-IS, policy-based routes (PBR), and segment routes (SR), (R2) reasoning on traffic load of billions of flows across a period of time, (R3) real-time failure-tolerance analysis. These requirements pose challenges in modeling the complex traffic behavior and maintaining the checking efficiency. Jingubang has successfully addressed these challenges. First, we propose the traffic distribution graph (or TDG), capable of modeling equal-cost multi-path (ECMP), packet rewriting, and tunneling, introduced by BGP/IS-IS, PBR, and SR, respectively. Second, we design an algorithm based on TDG to simulate traffic distribution for billions of flows across a time period both efficiently and accurately. Third, Jingubang proposes an incremental traffic simulation approach that first computes an incremental TDG and then simulates only thedifferentialtraffic distribution, avoiding the need to simulate the entire network traffic distribution from scratch. Jingubang has been used in the daily checking of our WAN for more than one year and prevented service downtime resulting from traffic load violations."
Optimizing RLHF Training for Large Language Models with Stage Fusion.,Yinmin Zhong; Zili Zhang; Bingyang Wu; Shengyu Liu; Yukun Chen; Changyi Wan; Hanpeng Hu; Lei Xia; Ranchen Ming; Yibo Zhu; Xin Jin 0008,2025,NSDI,https://www.usenix.org/conference/nsdi25/presentation/zhong,https://dblp.org/db/conf/nsdi/nsdi2025.html#ZhongZWLCWHXMZ025,"We present RLHFuse, an efficient training system with stage fusion for Reinforcement Learning from Human Feedback (RLHF). Due to the intrinsic nature of RLHF training, i.e., the data skewness in the generation stage and the pipeline bubbles in the training stage, existing RLHF systems suffer from low GPU utilization. RLHFuse breaks the traditional view of RLHF workflow as a composition of individual tasks, splitting each task into finer-grained subtasks, and performing stage fusion to improve GPU utilization. RLHFuse contains two key ideas. First, for generation and inference tasks, RLHFuse splits them into sample-level subtasks, enabling efficient inter-stage fusion to overlap the execution of generation and inference stages, thus mitigating the original generation bottleneck dominated by long-tailed samples. Second, for training tasks, RLHFuse breaks them into subtasks of micro-batches and performs intra-stage fusion to concurrently execute these subtasks in the training stage with a fused pipeline schedule, effectively mitigating the pipeline bubbles. The experiments show that RLHFuse increases the training throughput by up to 3.7×, compared to existing systems."
xBGP: Faster Innovation in Routing Protocols.,Thomas Wirtgen; Tom Rousseaux; Quentin De Coninck; Nicolas Rybowski; Randy Bush; Laurent Vanbever; Axel Legay; Olivier Bonaventure,2023,NSDI,https://www.usenix.org/conference/nsdi23/presentation/wirtgen,https://dblp.org/db/conf/nsdi/nsdi2023.html#WirtgenRCRBVLB23,"Internet Service Providers use routers from multiple vendors that support standardized routing protocols. Network operators deploy new services by tuning these protocols. Unfortunately, while standardization is necessary for interoperability, this is a slow process. As a consequence, new features appear very slowly in routing protocols.We propose a new implementation model for BGP, called xBGP, that enables ISPs to innovate by easily deploying BGP extensions in their multivendor network. We define a vendor-neutral xBGP API which can be supported by any BGP implementation and an eBPF Virtual Machine that allows executing extension code within these BGP implementations. We demonstrate the feasibility of our approach by extending both FRRouting and BIRD.We demonstrate seven different use cases showing the benefits that network operators can obtain using xBGP programs. We propose a verification toolchain that enables operators to compile and verify the safety properties of xBGP programs before deploying them. Our testbed measurements show that the performance impact of xBGP is reasonable compared to native code."
From Address Blocks to Authorized Prefixes: Redesigning RPKI ROV with a Hierarchical Hashing Scheme for Fast and Memory-Efficient Validation.,Zedong Ni; Yinbo Xu; Hui Zou; Yanbiao Li; Guang Cheng; Gaogang Xie,2025,NSDI,https://www.usenix.org/conference/nsdi25/presentation/ni,https://dblp.org/db/conf/nsdi/nsdi2025.html#NiXZLCX25,"Route Origin Validation (ROV) with Route Origin Authorizations (ROAs), built on top of the Resource Public Key Infrastructure (RPKI), serves as the only formally standardized and production-grade defense mechanism against route hijackings in global interdomain routing infrastructures. However, the widespread adoption of RPKI has introduced escalating scalability challenges in validating high volumes of route messages against massive ROA entries.In this paper, we attribute the performance bottleneck of existing ROV schemes to their underlying validation model, where the route is matched against rules in the form of address blocks. To overcome this bottleneck, we propose theAuthorized Prefix (AP) modelthat enables validation at the prefix granularity, and redesign RPKI ROV based on this new model with a hierarchical hashing scheme namedh2ROV. Extensive evaluations verifyh2ROV's superiority over state-of-the-art approaches in IPv4, with a speedup of $1.7× ∼ 9.8× in validation and a reduction of 49.3% ∼ 86.6% in memory consumption.  System emulations using real-world network topologies further demonstrateh2ROVconfines its impact to routing convergence to below 8.5% during update burst events, while reducing ROV-induced delays by 30.4% ∼ 64.7% compared to existing solutions."
"Fast, Approximate Vector Queries on Very Large Unstructured Datasets.",Zili Zhang; Chao Jin; Linpeng Tang; Xuanzhe Liu; Xin Jin 0008,2023,NSDI,https://www.usenix.org/conference/nsdi23/presentation/zhang-zili,https://dblp.org/db/conf/nsdi/nsdi2023.html#ZhangJTL023,"The breakthroughs in deep learning enable unstructured data to be represented as high-dimensional feature vectors for serving a wide range of applications. Processing vector queries (i.e., finding the nearest neighbor vectors for an input vector) for large unstructured datasets (with billions of items) is challenging, especially for applications with strict service level objectives (SLOs). Existing solutions trade query accuracy for latency, but without any guarantees, causing SLO violations.This paper presents Auncel, a vector query engine for large unstructured datasets that provides bounded query errors and bounded query latencies. The core idea of Auncel is to exploit local geometric properties of individual query vectors to build a precise error-latency profile (ELP) for each query. This profile enables Auncel to sample the right amount of data to process a given query while satisfying its error or latency requirements. Auncel is a distributed solution that can scale out with multiple workers. We evaluate Auncel with a variety of benchmarking datasets. The experimental results show that Auncel outperforms state-of-the-art approximate solutions by up to 10× on query latency with the same error bound (≤ 10%). In particular, Auncel only takes 25 ms to process a vector query on the DEEP1B dataset that contains one billion items with four c5.metal EC2 instances."

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First need to download dblp.xml.gz and unzip it\n",
    "# https://dblp.uni-trier.de/xml/ \n",
    "\n",
    "from lxml import etree\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import html\n",
    "import re\n",
    "from html.entities import name2codepoint\n",
    "\n",
    "TYPE = (\"inproceedings\", \"article\") # only pull paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncompressed dblp.xml.gz file\n",
    "dblp = \"dblp/dblp.xml\"\n",
    "\n",
    "# file for output\n",
    "output_file = \"output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PARAMETERS (if specifying target venue and publication years)\n",
    "\n",
    "IS_TARGET_VENUE = False # FALSE if there are no target venues\n",
    "TARGET_VENUES = {\n",
    "     # identifier in <booktitle> field in XML, if conference paper\n",
    "    \"SP\", \"USENIX Security Symposium\", \"CCS\", \"NDSS\", \"SOUPS\", \"EuroS&P\", \"ICCPS\", \"IROS\", \"ICRA\"\n",
    " }\n",
    "\n",
    "START_YEAR = 0 # oldest year to search (inclusive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- KEYWORDS AND DESIRED CATEGORIES -----\n",
    "DESIRED_CATEGORIES = {\n",
    "    \"ROBOT\", \"PRIVACY\"\n",
    "}\n",
    "\n",
    "CATEGORIES = {\n",
    "    \"ROBOT\": {\n",
    "        \"sensor\", \"robot\", \"robotic\"\n",
    "    },\n",
    "    \"PRIVACY\": {\n",
    "        \"privacy\"\n",
    "    }\n",
    "    # \"ROBOT\": {\n",
    "    #     \"robot\", \"robotics\", \"mobile robot\", \"robot mobility\", \"autonomous vehicle\", \"automated vehicle\", \"automated\",\n",
    "    #     \"autonomous\", \"self-driving\", \"cobot\", \"manipulator\", \"unmaned\", \"agrobot\", \n",
    "    #     \"delivery robot\", \"vacuum\", \"drone\", \"telepresence robot\", \"humanoid robot\", \"rover\",\n",
    "    #     \"inspection robot\", \"service robot\", \"home robot\", \"domestic robot\", \"assistive robot\",\n",
    "    #     \"companion robot\", \"food service robot\", \"surveillance robot\", \"robot navigation\", \"multirotor\",\n",
    "    #     \"quadrotor\", \"quadcopter\",\n",
    "    # },\n",
    "    # \"VISUAL\": {\n",
    "    #     \"camera\", \"rgb camera\", \"vision\", \"visual\", \"thermal imaging\", \"infrared camera\", \"infrared imaging\",\n",
    "    #     \"depth\", \"lidar\", \"structured light\", \"3d sensing\", \"stereo vision\"\n",
    "    # }, \n",
    "    # \"AUDIO\": {\n",
    "    #     \"microphone\", \"acoustic\", \"ultrasonic\", \"ultrasound\",\n",
    "    #     \"passive listening\", \"active audio sensing\", \"doppler sensing\", \"sound localization\"\n",
    "    # },\n",
    "    # \"RADAR\": {\n",
    "    #     \"radar\", \"radio frequency\", \"mmwave\", \"millimeter wave\", \"wifi sensing\",\n",
    "    #     \"fmcw\", \"rf sensing\", \"wireless sensing\", \n",
    "    # },\n",
    "    # \"OTHER_SENSORS\": {\n",
    "    #     \"accelerometer\", \"gyroscope\", \"ambient light\", \"light sensor\", \"temperature sensor\",\n",
    "    #     \"sensor fusion\", \"multi-modal sensing\", \"multimodal sensing\", \"light-based sensor\"\n",
    "    # }, \n",
    "    # \"PRIVACY_AND_SECURITY\": {\n",
    "    #     \"privacy\", \"security\", \"sensor privacy\", \"data privacy\", \"user privacy\", \"privacy-preserving\",\n",
    "    #     \"privacy preserving\", \"privacy enhancing\", \"safety\", \"resilience\", \"attack\",\n",
    "    #     \"privacy-aware\", \"privacy control\", \"data leakage\", \"privacy risk\", \"sensor leakage\",\n",
    "    #     \"user privacy\", \"data collection\", \"context-aware privacy\", \"surveillance\", \"anonymization\",\n",
    "    #     \"obfuscation\", \"masking\", \"cloaking\", \"blurring\", \"spoofing\", \"jamming\", \"sensor blocking\",\n",
    "    #     \"invisibility cloak\", \"retroreflective material\", \"adversarial\", \"privacy paradox\", \"trusted execution\", \"authentication\", \"fidelity\",\n",
    "    #     \"selective sensing\", \"privacy-aware sensing\", \"cybersecurity\", \"cyber attack\", \"cyberattack\", \"breach\", \"intrusion\", \"exploit\", \n",
    "    #     \"penetration testing\", \"pentest\", \"side-channel\", \"side channel\", \"replay attack\", \"eavesdropping\", \"data exfiltration\", \"phishing\", \n",
    "    #     \"secure\", \"digital signature\", \"blockchain\", \"access control\", \"key management\", \"identity management\", \"identification\", \"zero-proof knowledge\", \n",
    "    #     \"ZPK\"\n",
    "    # }, \n",
    "}\n",
    "\n",
    "# keywords that cannot be searched by substring\n",
    "RISKY_KEYWORDS = {\n",
    "    # \"ir\", \"rf\", \"imu\", \"ros\", \"uav\", \"ugv\", \"auv\", \"uav\", \"rov\", \"usv\"\n",
    "}\n",
    "\n",
    "CATEGORIES[\"RISKY_KEYWORDS\"] = RISKY_KEYWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- HELPER FUNCTIONS (NO CHANGES NEEDED) ---\n",
    "\n",
    "# checks if entry is a journal article\n",
    "def is_journal(entry):\n",
    "    return entry.tag == \"article\"\n",
    "\n",
    "# finds and extracts the information for the given tag for the given entry, if it exists\n",
    "def extract_tag(entry, tag):\n",
    "    t = entry.find(tag)\n",
    "    # if the tag and info exist, returns that info\n",
    "    return t.text.strip() if t is not None and t.text else None\n",
    "\n",
    "# checks if entry is from valid year\n",
    "def valid_year(entry):\n",
    "    year = extract_tag(entry, \"year\")\n",
    "    if year is None:\n",
    "        return None\n",
    "    try:\n",
    "        if int(year) >= START_YEAR:\n",
    "            return year\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "# checks if there is a keyword match\n",
    "def keyword_match(title, keyword):\n",
    "    title = title.lower()\n",
    "    keyword = keyword.lower()\n",
    "    if keyword in RISKY_KEYWORDS:\n",
    "        return re.search(rf'\\b{re.escape(keyword)}\\b', title, re.IGNORECASE) is not None\n",
    "    else:\n",
    "        return keyword in title\n",
    "\n",
    "# unwanted artifacts\n",
    "bad_artifacts = [\"Poster:\", \"extended abstract\", \"Demo:\", \"demo \", \"poster \"]\n",
    "\n",
    "# checks if title has keywords\n",
    "def check_title(entry):\n",
    "    title = extract_tag(entry, \"title\")\n",
    "    if not title:\n",
    "        return None\n",
    "    for item in bad_artifacts:\n",
    "        if item in title:\n",
    "            return None\n",
    "    categories = []\n",
    "    for category_name, keyword_set in CATEGORIES.items():\n",
    "        for keyword in keyword_set:\n",
    "            if keyword_match(title, keyword):\n",
    "                categories.append(category_name)\n",
    "    return (title, categories)\n",
    "\n",
    "# checks if desired categories are hit\n",
    "def desired_categories(categories):\n",
    "    if not categories:\n",
    "        return False\n",
    "    for item in DESIRED_CATEGORIES:\n",
    "        if item not in categories:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- VENUE HELPER FUNCTION (may need customization) ---\n",
    "\n",
    "def valid_venue(entry):\n",
    "    if IS_TARGET_VENUE:\n",
    "        if is_journal(entry):\n",
    "            key = entry.get(\"key\")\n",
    "            # customize to identifier in target JOURNAL key\n",
    "            if \"popets\" in key:\n",
    "                return \"PETS\"\n",
    "        else:\n",
    "            v = extract_tag(entry, \"booktitle\")\n",
    "            if v:\n",
    "                for venue in TARGET_VENUES:\n",
    "                    if venue == \"SOUPS\":\n",
    "                        if \"soups\" in v.lower():\n",
    "                            return \"SOUPS\"\n",
    "                    else:\n",
    "                        if re.search(rf'\\b{re.escape(venue)}\\b', v):\n",
    "                            return venue\n",
    "        return None\n",
    "    else:\n",
    "        if is_journal(entry):\n",
    "            key = entry.get(\"key\")\n",
    "            match = re.search(r\"^journals/([^/]+)/\", key)\n",
    "            if match:\n",
    "                result = match.group(1)\n",
    "                return result\n",
    "        else:\n",
    "            v = extract_tag(entry, \"booktitle\")\n",
    "            return v or None\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAIN HELPER FUNCTIONS (NO CHANGES NEEDED) ---\n",
    "\n",
    "# checks if entry is valid, and returns all necessary info if valid\n",
    "def extract_entry(entry):\n",
    "    year = valid_year(entry)\n",
    "    venue = valid_venue(entry)\n",
    "    \n",
    "    if not year or not venue:\n",
    "        return None\n",
    "   \n",
    "    tc = check_title(entry)\n",
    "    if not tc:\n",
    "        return None\n",
    "    title, categories = tc\n",
    "\n",
    "    if not desired_categories(categories):\n",
    "        return None\n",
    "\n",
    "    ee = extract_tag(entry, \"ee\")\n",
    "    url = extract_tag(entry, \"url\")\n",
    "    \n",
    "    if url and not url.startswith(\"http\"):\n",
    "        url = \"https://dblp.org/\" + url\n",
    "   \n",
    "    authors = [a.text.strip() for a in entry.findall(\"author\") if a.text]\n",
    "    if not authors:\n",
    "        authors = [\"N/A\"]\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"category\": \";\".join(categories),\n",
    "        \"authors\": \"; \".join(authors),\n",
    "        \"year\": year,\n",
    "        \"venue\": venue,\n",
    "        \"ee\": ee,\n",
    "        \"url\": url,\n",
    "    }\n",
    "\n",
    "# --- PARSER ---\n",
    "def parse_dblp(xml_file, skip=0, max=None):\n",
    "    results = []\n",
    "    total = 0\n",
    "    skipped = 0\n",
    "\n",
    "    parser = etree.XMLParser(load_dtd=False, no_network=True, recover=True, resolve_entities=False)\n",
    "    \n",
    "    with open(xml_file, 'rb') as file:  # open file as binary\n",
    "        try:\n",
    "            context = etree.iterparse(\n",
    "                file,\n",
    "                events=('end',),\n",
    "                tag=TYPE,\n",
    "                load_dtd=False,\n",
    "                no_network=True,\n",
    "                resolve_entities=False,\n",
    "                recover=True,\n",
    "                huge_tree=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Could not initialize parser: {e}\")\n",
    "            return []\n",
    "        \n",
    "        print(\"Parsing DBLP... (this may take several minutes)\")\n",
    "        for _, element in tqdm(context, desc=\"Entries processed\", unit=\"entry\"):\n",
    "            total += 1\n",
    "\n",
    "            if total < skip:\n",
    "                continue\n",
    "\n",
    "            if max and total >= max:\n",
    "                break\n",
    "        \n",
    "            try:\n",
    "                record = extract_entry(element)\n",
    "                if record:\n",
    "                    results.append(record)\n",
    "            except Exception as e:\n",
    "                skipped += 1\n",
    "                print(f\"Skipping entry {total} due to error: {e}\")\n",
    "                try:\n",
    "                    print(etree.tostring(element, pretty_print=True, encoding=\"unicode\"))\n",
    "                except Exception as sub_e:\n",
    "                    print(f\"Could not print element {total}: {sub_e}\")\n",
    "            finally:\n",
    "                # Free memory\n",
    "                try:\n",
    "                    element.clear()\n",
    "                    while element.getprevious() is not None:\n",
    "                        del element.getparent()[0]\n",
    "                except Exception as cleanup_e:\n",
    "                    print(f\"Cleanup error at entry {total}: {cleanup_e}\")\n",
    "                    continue\n",
    "\n",
    "    print(f\"\\nTotal entries parsed: {total}\")\n",
    "    print(f\"Total matching papers: {len(results)}\")\n",
    "    print(f\"Total skipped entries: {skipped}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing DBLP... (this may take several minutes)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entries processed: 0entry [00:00, ?entry/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Entries processed: 7691562entry [01:46, 72329.76entry/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total entries parsed: 7691562\n",
      "Total matching papers: 870\n",
      "Total skipped entries: 0\n",
      "870\n",
      "Saved to output.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- MAIN DBLP SCRAPER ----\n",
    "if __name__ == \"__main__\":\n",
    "    papers = parse_dblp(dblp)\n",
    "\n",
    "    df = pd.DataFrame(papers)\n",
    "    print(len(df))\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(\"Saved to \" + output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
